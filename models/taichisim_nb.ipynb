{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf5b80e-57ba-4c42-9f0f-62d4de6f8f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['font.size'] = 20\n",
    "matplotlib.rcParams['figure.figsize'] = (14,9)\n",
    "matplotlib.rcParams['savefig.bbox'] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e1735936-7cf4-42b9-baa8-862ed3483f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'resnet' from '/Users/albertxu/AI4AM/models/resnet.py'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0072226-ec90-428a-9cf6-d70f298ce444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import pickle\n",
    "import resnet\n",
    "\n",
    "import taichiUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2132729b-a98f-4def-92fd-1f335e649a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ex):\n",
    "    ex['image'] = tf.image.resize(tf.image.convert_image_dtype(ex['image'], tf.float32), [250, 250])\n",
    "    return ex\n",
    "\n",
    "def pred(ex):\n",
    "    return (ex['n_seq'] % 10 == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4535ee39-995c-426b-bcfa-5ef9c0d7ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tfds.load('taichiSim', split='train').map(preprocess).filter(flter).batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b18e8746-1f58-4acb-b9ae-3d6103fb58d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.dataset_ops._NumpyIterator at 0x15d887ac0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "dce61ca8-5e96-4f3e-bb54-901452b3d917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.92720532,  0.19170223, -0.35352325, -0.63758558,  0.27806041,\n",
       "        -0.70423704, -0.9171735 , -0.96169937,  0.        ,  0.96170008,\n",
       "         0.09230772,  0.        ,  0.62019706],\n",
       "       [-0.7789709 ,  0.48633233,  0.66862869, -0.08112147, -0.7618475 ,\n",
       "         0.60673964, -0.72283632,  0.48158008,  0.        , -0.48157972,\n",
       "        -0.48222539,  0.        , -0.0381093 ],\n",
       "       [ 0.26570737,  0.76882315,  0.71354294, -0.20474648,  0.13693374,\n",
       "         0.7925958 ,  0.87967128,  0.08187816,  0.        , -0.08187791,\n",
       "        -0.1724806 ,  0.        , -0.21241236],\n",
       "       [ 0.74408114,  0.9485274 , -0.52203274,  0.4269807 ,  0.69549406,\n",
       "        -0.12622169, -0.14873271,  0.09647024,  0.        , -0.09647012,\n",
       "         0.93993342,  0.        ,  0.67713666],\n",
       "       [ 0.49710172,  0.65732813,  0.02225685, -0.83988363,  0.02866478,\n",
       "        -0.63391912, -0.05488397,  0.93139273,  0.        , -0.93139213,\n",
       "        -0.33360454,  0.        ,  0.52064562],\n",
       "       [ 0.12530425,  0.6085512 ,  0.17507744, -0.05203134, -0.97255373,\n",
       "         0.7648676 , -0.08832797, -0.99537683,  0.        ,  0.99537671,\n",
       "         0.31032297,  0.        , -0.46816993],\n",
       "       [ 0.53076404,  0.22849397,  0.01366806, -0.12187149,  0.24672015,\n",
       "        -0.24801059,  0.00359711,  0.90665781,  0.        , -0.90665722,\n",
       "        -0.58419704,  0.        , -0.60668898],\n",
       "       [ 0.18361945,  0.25243688,  0.77969074, -0.35385457,  0.17049235,\n",
       "         0.48423675, -0.55692434,  0.38724953,  0.        , -0.38724941,\n",
       "        -0.8439514 ,  0.        ,  0.30750155],\n",
       "       [-0.9103682 ,  0.3647792 ,  0.85513687, -0.61011195, -0.13842846,\n",
       "         0.05364013,  0.73656118,  0.49787104,  0.        , -0.49787065,\n",
       "         0.59171647,  0.        , -0.44004822],\n",
       "       [ 0.23297925,  0.62753767, -0.89997005,  0.08012336,  0.40275043,\n",
       "         0.95010346,  0.48992777, -0.83968121,  0.        ,  0.83968145,\n",
       "        -0.60597456,  0.        , -0.45809579],\n",
       "       [ 0.52840471,  0.34671336,  0.87863636, -0.29730806, -0.42730805,\n",
       "        -0.89857846,  0.39612299, -0.2075789 ,  0.        ,  0.20757914,\n",
       "        -0.03613234,  0.        ,  0.80280352],\n",
       "       [-0.64116299,  0.65966994,  0.5125761 , -0.86716884, -0.14886011,\n",
       "         0.71195692,  0.38168609, -0.14905086,  0.        ,  0.14905135,\n",
       "        -0.79592264,  0.        , -0.15805292],\n",
       "       [-0.03060619,  0.04242622, -0.49862957, -0.16326587,  0.56770444,\n",
       "        -0.90144795,  0.86141688, -0.12782155,  0.        ,  0.12782216,\n",
       "         0.03271898,  0.        , -0.43595791],\n",
       "       [-0.26887554,  0.79192984, -0.92269039,  0.91831475, -0.44104832,\n",
       "         0.13486634,  0.08131788, -0.38705719,  0.        ,  0.38705766,\n",
       "         0.27187532,  0.        ,  0.34873223],\n",
       "       [-0.78362054,  0.26261944,  0.13324451,  0.53146261, -0.35371763,\n",
       "        -0.73276848,  0.90288144, -0.44054812,  0.        ,  0.44054887,\n",
       "        -0.86279905,  0.        , -0.68017149],\n",
       "       [ 0.68695343,  0.93382084,  0.38825989, -0.2726337 , -0.02645369,\n",
       "         0.91831136,  0.17114864, -0.63701296,  0.        ,  0.63701373,\n",
       "        -0.66713756,  0.        ,  0.03076506],\n",
       "       [ 0.87428588,  0.20755874, -0.00327015, -0.64900076, -0.73112869,\n",
       "        -0.03717673,  0.7554158 ,  0.58960432,  0.        , -0.5896042 ,\n",
       "        -0.33124352,  0.        ,  0.73805094],\n",
       "       [ 0.19786277,  0.52944016, -0.62827778,  0.6772033 ,  0.62112576,\n",
       "        -0.56006449, -0.03131668,  0.60798538,  0.        , -0.60798526,\n",
       "        -0.96163416,  0.        , -0.49047732],\n",
       "       [-0.67636907,  0.56016612,  0.8240881 , -0.83085525,  0.45640796,\n",
       "        -0.50154483, -0.87364936, -0.9026593 ,  0.        ,  0.90265971,\n",
       "         0.58630836,  0.        , -0.33652925],\n",
       "       [ 0.73056835,  0.48822314, -0.35831928,  0.39765474,  0.3635461 ,\n",
       "        -0.44239336, -0.08543666, -0.39592275,  0.        ,  0.39592287,\n",
       "         0.77739155,  0.        ,  0.04666042]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taichiUtil.dat2vec(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8ba21d2a-81ac-4f2b-b2a6-cd34f9b817c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=bool, numpy=\n",
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False])>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z['n_seq'] % 10 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d43de43b-a06b-4efe-846e-1a2f9984bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "052fa38b-51aa-4455-9cac-ce8096314e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0.21091919, 0.23315436, 0.3898561 , 0.46161216, 0.42456526,\n",
       "       0.36879563, 0.4296146 , 0.3775429 , 0.21344475, 0.38494688,\n",
       "       0.4292607 , 0.25382555, 0.34540907, 0.30966866, 0.23245691,\n",
       "       0.453043  , 0.48114288, 0.3796794 , 0.24854463, 0.45958525],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z['ex_scale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ab89d784-fb51-4cad-b020-1165f6d884ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Scalar tensor has no `len()`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g7/85rmgp356tb3k172104gjdp80000gn/T/ipykernel_87409/2570628843.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtaichiUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdat2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/AI4AM/models/taichiUtil.py\u001b[0m in \u001b[0;36mdat2vec\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Transforms 'control vector' into a [-1, 1] random uniform vector. (non-random params are 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdat2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ex_scale'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ex_scale'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m.35\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m.15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msgn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ex_v0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0;34m\"\"\"Returns the length of the first dimension in the Tensor.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Scalar tensor has no `len()`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Scalar tensor has no `len()`"
     ]
    }
   ],
   "source": [
    "taichiUtil.dat2vec(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bcc7ba3-5c8f-4e37-b81f-bf0aa2fc4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "vals_ds = tfds.load('taichiSim', split=[\n",
    "    tfds.core.ReadInstruction('tmp', from_=k, to=k+10, unit='%')\n",
    "    for k in range(0, 100, 10)], batch_size=batch_size)\n",
    "trains_ds = tfds.load('taichiSim', split=[\n",
    "    (tfds.core.ReadInstruction('tmp', to=k, unit='%') +\n",
    "     tfds.core.ReadInstruction('tmp', from_=k+10, unit='%'))\n",
    "    for k in range(0, 100, 10)], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4028d418-a7d5-473c-9b00-e0c9af915eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMo(tf.keras.Model):\n",
    "    def __init__(self, im_head, n_class=4):\n",
    "        super(MyMo, self).__init__()\n",
    "        \n",
    "        self.im_head = im_head\n",
    "        self.fc1 = tf.keras.layers.Dense(units=n_class, activation=tf.keras.activations.softmax)\n",
    "#         self.fc2 = tf.keras.layers.Dense(units=n_class, activation=tf.keras.activations.softmax)\n",
    "\n",
    "#     def call(self, inputs, training=None):\n",
    "    def call(self, im, uvec, training=None):\n",
    "#         im, uvec = inputs\n",
    "        x = self.im_head(im, training=training)\n",
    "        x = tf.concat([x, uvec], axis=-1)\n",
    "        out = self.fc1(x, training=training)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9c7e2b82-4208-4fc7-b4a7-27209cb98e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "resn = resnet.resnet_18(drop_p=0, n_class=2048)\n",
    "model = MyMo(resn, n_class=2)\n",
    "objective = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b5d45cdd-1af3-4857-aa71-995fe0d1f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(m, x, y, _train=True):\n",
    "    _y = m(x, training=_train)\n",
    "    return objective(y_true=y, y_pred=_y)\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, _train=True)\n",
    "        return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "876730b8-5148-4a8b-81f0-2d21e39aa792",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "502d62a4-395c-4488-8ae1-0c1ef11fd23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[0.46993318, 0.5300668 ],\n",
       "       [0.49032217, 0.5096779 ],\n",
       "       [0.4872703 , 0.51272964],\n",
       "       [0.5056    , 0.49440008],\n",
       "       [0.48715752, 0.5128424 ],\n",
       "       [0.49752817, 0.50247186],\n",
       "       [0.5255966 , 0.47440338],\n",
       "       [0.50974506, 0.49025497],\n",
       "       [0.510732  , 0.489268  ],\n",
       "       [0.5020897 , 0.49791026]], dtype=float32)>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in train:\n",
    "    break\n",
    "model(x['image'], taichiUtil.dat2vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b0496133-c81c-41a7-91e8-7a1a53b9df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.im_head(x['image'])\n",
    "b = taichiUtil.dat2vec(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "47649211-b9b5-46aa-a501-a88b822a1cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2061), dtype=float32, numpy=\n",
       "array([[ 5.2245375e-04,  4.8988278e-04,  5.0078891e-04, ...,\n",
       "         5.8630836e-01,  0.0000000e+00, -3.3652925e-01],\n",
       "       [ 5.2293635e-04,  4.8946624e-04,  5.0087686e-04, ...,\n",
       "        -2.0492473e-01,  0.0000000e+00,  1.5815520e-01],\n",
       "       [ 5.2124937e-04,  4.8952823e-04,  5.0065818e-04, ...,\n",
       "        -6.2110686e-01,  0.0000000e+00,  9.4827080e-01],\n",
       "       ...,\n",
       "       [ 5.2165560e-04,  4.8970233e-04,  5.0077878e-04, ...,\n",
       "        -5.8419704e-01,  0.0000000e+00, -6.0668898e-01],\n",
       "       [ 5.2148494e-04,  4.8914819e-04,  5.0076074e-04, ...,\n",
       "        -3.6132336e-02,  0.0000000e+00,  8.0280352e-01],\n",
       "       [ 5.2131800e-04,  4.8948126e-04,  5.0075003e-04, ...,\n",
       "         3.4572017e-01,  0.0000000e+00,  6.1257815e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([a, b], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1c2ffdd5-99b5-44eb-b0c6-3365f72caea6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape (10, 13) must have rank 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g7/85rmgp356tb3k172104gjdp80000gn/T/ipykernel_87409/3463567874.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/g7/85rmgp356tb3k172104gjdp80000gn/T/ipykernel_87409/731910500.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, im, uvec, training)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#         im, uvec = inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1762\u001b[0m     \u001b[0;31m# TODO(keveman): Implement a standalone type and shape checker.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m       ops.convert_to_tensor(\n\u001b[0m\u001b[1;32m   1765\u001b[0m           \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat_dim\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_has_rank\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m   1039\u001b[0m     \"\"\"\n\u001b[1;32m   1040\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape %s must have rank %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape (10, 13) must have rank 0"
     ]
    }
   ],
   "source": [
    "model(*inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e5034226-8ea0-42b0-9084-1209b8b07044",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = trains_ds[0]\n",
    "val = vals_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d99b3-e326-49dd-8b3d-bef6f0b4ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "n_epoch = 500\n",
    "for epoch in range(n_epoch):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    test_epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    test_epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    \n",
    "    train2 = train.shuffle(buffer_size=50)\n",
    "    for ex in train2:\n",
    "        x = tf.image.convert_image_dtype(ex['image'], tf.float32)\n",
    "        ys = taichiUtil.dat2vec(ex)\n",
    "        # class_encode = tf.reshape(tf.one_hot((ys[:,3:7] > 0).astype(int), 2), (-1, 8))\n",
    "        y = (ys[:,3] > 0).astype(int)\n",
    "        l, grads = grad(model, x, y)\n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        epoch_loss_avg.update_state(l)\n",
    "        epoch_accuracy.update_state(y, model(x, training=True))\n",
    "    \n",
    "    print(f'Epoch {epoch:03d}, Train Loss: {epoch_loss_avg.result():.3f}, Acc: {epoch_accuracy.result():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "38db6334-6d5d-47f9-8a99-54759c9300ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b75e68-6e7b-4461-b42f-f4f087eb402c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
